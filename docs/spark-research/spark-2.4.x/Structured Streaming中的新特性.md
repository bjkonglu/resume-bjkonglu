## Structured Streamingä¸­çš„æ–°ç‰¹æ€§
### èƒŒæ™¯
æ˜¨å¤©ï¼Œä¹Ÿå°±æ˜¯11.08ï¼ŒSparkå‘å¸ƒäº†2.4.0ç‰ˆæœ¬ã€‚å…¶ä¸­åŒ…å«å¾ˆå¤šæœ‰ç”¨çš„æ–°ç‰¹æ€§ï¼Œè®©æˆ‘æœ€æ„Ÿå…´è¶£çš„æ–°ç‰¹æ€§å°±æ˜¯*Flexible Streaming Sink*ã€‚åœ¨2.4.0ç‰ˆæœ¬æœªå‘å¸ƒä¹‹å‰ï¼Œä½¿ç”¨Structured Streamingæ„å»ºå®æ—¶è®¡ç®—åº”ç”¨æ—¶ï¼Œæœ‰ä¸ªç—›ç‚¹å°±æ˜¯éœ€è¦ç”¨æˆ·è‡ªå®šä¸€äº›sinkï¼Œä¾‹å¦‚å®æ—¶å†™å…¥MySQLã€HBaseçš„ç»„ä»¶ã€‚è¿™æ ·å¯¼è‡´å¼€å‘éš¾åº¦æ¯”è¾ƒå¤§ï¼Œè°ƒè¯•èµ·æ¥æ¯”è¾ƒè´¹åŠ²ã€‚ä¸è¿‡åœ¨2.4.0ç‰ˆæœ¬ä¸­ï¼ŒSparkç»ˆäºè§£å†³äº†è¿™ä¸ªç—›ç‚¹ï¼Œæ¨å‡ºäº†*Flexible Streaming Sink*ã€‚

### Flexible Streaming Sinkç®€ä»‹
é’ˆå¯¹è®¸å¤šæ‰©å±•çš„å­˜å‚¨ç³»ç»Ÿï¼ŒSparkå·²ç»æœ‰æ‰¹å¤„ç†çš„Connectorï¼Œä½†æ˜¯è¿™äº›æ‰©å±•çš„å­˜å‚¨ç³»ç»Ÿä¸æ˜¯éƒ½æœ‰æµçš„sinkã€‚*Flexible Streaming Sink*å°±æ˜¯ç”¨æ¥å¤„ç†è¿™ä¸ªé—®é¢˜çš„ï¼Œ*streamingDF.writeStream.foreachBatch(...)* å…è®¸ç”¨æˆ·ä½¿ç”¨batch data writeræ¥å†™æ¯ä¸ªmicbatchï¼Œä¸¾ä¸ªä¾‹å­ğŸŒ°
```scala
//stream write into mysql
streamingDF.writeStream
.foreachBatch { (batchDF: DataFrame, batchId: Long) =>

    batchDF.write       // Use mysql batch data source to write streaming out
      .mode("append")
      .jdbc(url, tableName, prop)
  }
```
æ­¤å¤–ï¼Œç”¨æˆ·ä¹Ÿå¯ä»¥ä½¿ç”¨ä¸Šè¿°æ¥å£å°†micro-batch outputå†™å…¥å…¶ä»–Sparkæš‚ä¸æ”¯æŒçš„å­˜å‚¨ç³»ç»Ÿä¸­ï¼ŒåŒæ—¶*foreachBatch*å¯ä»¥é¿å…é‡å¤è®¡ç®—ï¼Œå°†æ•°æ®å†™å…¥åˆ°ä¸åŒçš„å­˜å‚¨ã€‚
```scala
streamingDF.writeStream.foreachBatch { (batchDF: DataFrame, batchId: Long) =>
  batchDF.cache()
  batchDF.write.format(...).save(...)  // location 1
  batchDF.write.format(...).save(...)  // location 2
  batchDF.uncache()
}
```

### åè®°
Spark2.4.0ç‰ˆæœ¬ä¸­çš„SSè¿˜æ˜¯æå‡ä¸å°‘çš„ï¼Œé’ˆå¯¹æ•°æ®ä¸­çš„ETLåœºæ™¯è¿˜æ˜¯éå¸¸é€‚ç”¨çš„ 
